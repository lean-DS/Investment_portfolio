# -*- coding: utf-8 -*-
"""GCP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mr7eYs1wORNswHObAutUZr2M6e9i2vf0
"""

import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
from typing import List, Tuple
import os, time, json, random, hashlib
from datetime import datetime, timedelta

# ------------------- Page Setup ------------------- #
st.set_page_config(page_title="AI Portfolio Recommender", layout="wide")
st.title("AI Portfolio Recommender")

# ------------------- Step 1: Investor Inputs ------------------- #
st.header("Investor Profile")

col1, col2, col3 = st.columns(3)
with col1:
    age = st.number_input("Age", min_value=18, max_value=100, value=30)
with col2:
    goal = st.selectbox("Investment Goal", ["Capital Growth", "Dividend Income", "Balanced"])
with col3:
    horizon = st.slider("Investment Horizon (years)", 1, 10, 3)

amount = st.number_input("Investment Amount (in Pounds)", min_value=1000, step=1000, value=10000)

def recommend_risk_by_age(a: int) -> str:
    if a < 30: return "Aggressive"
    if a < 50: return "Moderate"
    return "Conservative"

recommended_risk = recommend_risk_by_age(age)
st.markdown(f"**System Suggestion:** Based on age, consider **{recommended_risk}** risk")

risk_profile = st.selectbox(
    "Preferred Risk Profile",
    ["Conservative", "Moderate", "Aggressive"],
    index=["Conservative", "Moderate", "Aggressive"].index(recommended_risk)
)

def assign_beta_range(profile: str) -> Tuple[float, float]:
    if profile == "Conservative": return (0.5, 1.0)
    if profile == "Moderate":     return (1.1, 1.3)
    if profile == "Aggressive":   return (1.4, 2.2)
    return (1.0, 1.3)

min_beta, max_beta = assign_beta_range(risk_profile)
st.success(f"Target Portfolio Beta: {min_beta} â€“ {max_beta}")

equity_percent = max(0, 100 - age)
debt_percent = 100 - equity_percent
st.info(f"Suggested Split: **{equity_percent}% Equity**, **{debt_percent}% Debt/ETFs**")

if st.button("Build Dynamic Universe"):
    st.session_state.user_inputs = dict(
        age=int(age), goal=goal, horizon=int(horizon), amount=float(amount),
        risk_profile=risk_profile, min_beta=float(min_beta), max_beta=float(max_beta),
        equity_percent=int(equity_percent), debt_percent=int(debt_percent)
    )
    st.experimental_rerun()

# ===================== Helpers (single-file) ===================== #
def _flatten_columns(df: pd.DataFrame) -> pd.DataFrame:
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = [' '.join([str(x) for x in tup if x is not None]).strip()
                      for tup in df.columns.values]
    else:
        df.columns = [str(c).strip() for c in df.columns]
    return df

def _find_ticker_col(df: pd.DataFrame) -> str | None:
    for c in df.columns:
        cl = str(c).strip().lower()
        if any(k in cl for k in ["epic","ticker","symbol","code"]):
            return c
    return None

def _download_ohlcv(ticker: str) -> pd.DataFrame | None:
    df = yf.download(ticker, period="2y", interval="1d", progress=False, auto_adjust=False)
    if df is None or df.empty: return None
    return df

def _download_index_close(symbol: str = "ACWI") -> pd.Series | None:
    df = yf.download(symbol, period="2y", interval="1d", progress=False)
    if df is None or df.empty or "Close" not in df.columns: return None
    return df["Close"].dropna()

def _calculate_beta_vs(close_stock: pd.Series, close_bench: pd.Series) -> float | None:
    sret = close_stock.pct_change().dropna()
    bret = close_bench.pct_change().dropna()
    aligned = pd.concat([sret, bret], axis=1, join="inner").dropna()
    if len(aligned) < 30: return None
    aligned.columns = ["stock","bench"]
    bvar = aligned["bench"].var()
    if not bvar or pd.isna(bvar): return None
    beta = aligned.cov().iloc[0,1] / bvar
    return round(float(beta), 2)

# ---------- US/UK universes ----------
@st.cache_data(show_spinner=False, ttl=3600)
def fetch_sp500_universe(max_names: int = 600) -> List[str]:
    url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
    tables = pd.read_html(url)
    for t in tables:
        t = _flatten_columns(t)
        if "Symbol" in t.columns or "symbol" in [c.lower() for c in t.columns]:
            col = "Symbol" if "Symbol" in t.columns else [c for c in t.columns if c.lower()=="symbol"][0]
            syms = t[col].dropna().astype(str).str.upper().str.strip().tolist()
            return [s.replace(".", "-") for s in syms][:max_names]
    return []

@st.cache_data(show_spinner=False, ttl=3600)
def fetch_ftse_100() -> List[str]:
    url = "https://en.wikipedia.org/wiki/FTSE_100_Index"
    tables = pd.read_html(url)
    for t in tables:
        t = _flatten_columns(t)
        col = _find_ticker_col(t)
        if col is None: continue
        syms = t[col].dropna().astype(str).str.upper().str.strip().tolist()
        return [s if s.endswith(".L") else f"{s}.L" for s in syms]
    return []

@st.cache_data(show_spinner=False, ttl=3600)
def fetch_ftse_250() -> List[str]:
    url = "https://en.wikipedia.org/wiki/FTSE_250_Index"
    tables = pd.read_html(url)
    for t in tables:
        t = _flatten_columns(t)
        col = _find_ticker_col(t)
        if col is None: continue
        syms = t[col].dropna().astype(str).str.upper().str.strip().tolist()
        return [s if s.endswith(".L") else f"{s}.L" for s in syms]
    return []

def universal_equity_universe() -> List[str]:
    us = fetch_sp500_universe()
    uk = list(set(fetch_ftse_100() + fetch_ftse_250()))
    return list(dict.fromkeys(us + uk))

# ---------- Debt ETF scrapers (multi-source with caching) ----------
_CACHE_DIR = ".cache_etfs"
os.makedirs(_CACHE_DIR, exist_ok=True)

def _cache_path(key: str) -> str:
    return os.path.join(_CACHE_DIR, hashlib.md5(key.encode()).hexdigest() + ".json")

def _load_cache(key: str, ttl_hours: int = 24):
    p = _cache_path(key)
    if not os.path.exists(p): return None
    try:
        mtime = datetime.fromtimestamp(os.path.getmtime(p))
        if datetime.utcnow() - mtime > timedelta(hours=ttl_hours): return None
        with open(p, "r") as f: return json.load(f)
    except Exception:
        return None

def _save_cache(key: str, data):
    try:
        with open(_cache_path(key), "w") as f: json.dump(data, f)
    except Exception:
        pass

def _scrape_us_bond_etfs() -> pd.DataFrame:
    key = "us_bond_etfs_wiki"
    cached = _load_cache(key)
    if cached is not None:
        return pd.DataFrame(cached)
    url = "https://en.wikipedia.org/wiki/List_of_American_exchange-traded_funds"
    try:
        dfs = pd.read_html(url)
    except Exception:
        return pd.DataFrame(columns=["Ticker","Name"])
    rows = []
    for t in dfs:
        t = _flatten_columns(t)
        tick_col = next((c for c in t.columns if "ticker" in str(c).lower() or "symbol" in str(c).lower()), None)
        name_col = next((c for c in t.columns if "name" in str(c).lower() or "fund" in str(c).lower()), None)
        asset_col = next((c for c in t.columns if "asset" in str(c).lower()), None)
        if tick_col is None: continue
        temp = t.copy()
        temp["__ticker__"] = temp[tick_col].astype(str).str.upper().str.strip()
        temp["__name__"]   = temp[name_col].astype(str) if name_col is not None else ""
        temp["__asset__"]  = temp[asset_col].astype(str).str.lower() if asset_col is not None else ""
        mask = (
            temp["__asset__"].str.contains("bond|fixed", na=False) |
            temp["__name__"].astype(str).str.lower().str.contains(
                "bond|treasury|agg|tips|inflation|credit|corporate|high yield|muni|municipal|short|intermediate|long", na=False
            )
        )
        keep = temp.loc[mask, ["__ticker__","__name__"]].rename(columns={"__ticker__":"Ticker","__name__":"Name"})
        if not keep.empty: rows.append(keep)
    out = pd.concat(rows, ignore_index=True).drop_duplicates("Ticker") if rows else pd.DataFrame(columns=["Ticker","Name"])
    if not out.empty:
        out["Ticker"] = out["Ticker"].astype(str).str.upper().str.strip()
        out = out[~out["Ticker"].str.endswith(".L")]
    _save_cache(key, out.to_dict(orient="records"))
    return out

def _scrape_uk_bond_etfs() -> pd.DataFrame:
    key = "uk_bond_etfs_wiki"
    cached = _load_cache(key)
    if cached is not None:
        return pd.DataFrame(cached)
    urls = [
        "https://en.wikipedia.org/wiki/List_of_Exchange-traded_funds_listed_on_the_London_Stock_Exchange",
        "https://en.wikipedia.org/wiki/List_of_exchange-traded_funds"
    ]
    rows = []
    for url in urls:
        try:
            dfs = pd.read_html(url)
        except Exception:
            continue
        for t in dfs:
            t = _flatten_columns(t)
            tick_col = next((c for c in t.columns if any(k in str(c).lower() for k in ["ticker","epic","symbol"])), None)
            name_col = next((c for c in t.columns if any(k in str(c).lower() for k in ["name","fund","etf"])), None)
            if tick_col is None: continue
            temp = t.copy()
            temp["__ticker__"] = temp[tick_col].astype(str).str.upper().str.replace(" ", "", regex=False).str.strip()
            temp["__name__"]   = temp[name_col].astype(str) if name_col is not None else ""
            mask = temp["__name__"].astype(str).str.lower().str.contains(
                "bond|gilt|treasury|credit|corporate|tips|inflation|aggregate|gilts|short|intermediate|long", na=False
            )
            keep = temp.loc[mask, ["__ticker__","__name__"]].rename(columns={"__ticker__":"Ticker","__name__":"Name"})
            if not keep.empty: rows.append(keep)
    out = pd.concat(rows, ignore_index=True).drop_duplicates("Ticker") if rows else pd.DataFrame(columns=["Ticker","Name"])
    if not out.empty:
        out["Ticker"] = out["Ticker"].astype(str)
        out["Ticker"] = out["Ticker"].apply(lambda x: x if x.endswith(".L") else f"{x}.L")
    _save_cache(key, out.to_dict(orient="records"))
    return out

def _validate_rank_debt(tickers: List[str], want: int) -> pd.DataFrame:
    rows = []
    for t in tickers:
        df = _download_ohlcv(t)
        if df is None or df.empty: continue
        vol = float(df["Volume"].dropna().tail(60).mean()) if "Volume" in df.columns else 0.0
        rows.append((t, vol))
    if not rows: return pd.DataFrame(columns=["Ticker","Avg Volume (60d)"])
    out = (pd.DataFrame(rows, columns=["Ticker","Avg Volume (60d)"])
             .sort_values("Avg Volume (60d)", ascending=False)
             .drop_duplicates("Ticker")
             .head(want)
             .reset_index(drop=True))
    return out

# ---------- Goal & horizon features ----------
def _total_return(close: pd.Series, days: int) -> float:
    if len(close) < days + 1: return np.nan
    return float(close.iloc[-1] / close.iloc[-1 - days] - 1.0)

def _max_drawdown(close: pd.Series) -> float:
    roll_max = close.cummax()
    dd = (close / roll_max - 1.0)
    return float(dd.min())

def _volatility(daily_ret: pd.Series) -> float:
    return float(daily_ret.std())

def _ttm_dividend_yield(ticker: str, price_now: float) -> float:
    try:
        t = yf.Ticker(ticker)
        div = t.dividends
        if div is None or div.empty or price_now <= 0: return 0.0
        recent = div[div.index >= (div.index.max() - pd.Timedelta(days=365))]
        total = float(recent.sum()) if not recent.empty else 0.0
        return float(total / price_now)
    except Exception:
        return 0.0

def _normalize(s: pd.Series, invert: bool=False) -> pd.Series:
    s = s.replace([np.inf, -np.inf], np.nan)
    s = s.fillna(s.median()) if not s.isna().all() else s.fillna(0.0)
    lo, hi = s.min(), s.max()
    if hi == lo: out = pd.Series(0.5, index=s.index)
    else:        out = (s - lo) / (hi - lo)
    return 1 - out if invert else out

def _equity_weights(goal: str, horizon_years: int) -> dict:
    short = horizon_years < 3
    if goal == "Capital Growth":
        return {"mom3":0.40 if short else 0.25, "mom6":0.25, "mom12":0.15 if short else 0.30,
                "vol":0.10, "dd":0.10, "yield":0.10 if not short else 0.00}
    if goal == "Dividend Income":
        return {"yield":0.55 if not short else 0.45, "vol":0.15, "dd":0.15, "mom3":0.05, "mom6":0.05, "mom12":0.05}
    return {"mom3":0.20 if short else 0.15, "mom6":0.20, "mom12":0.20, "vol":0.15, "dd":0.15, "yield":0.10 if not short else 0.05}

# ---------- Main picker ----------
def dynamic_universal_picker(user_inputs: dict,
    scan_cap_us: int = 250, scan_cap_uk: int = 200,
    want_equities: int = 50, want_debt: int = 30) -> Tuple[pd.DataFrame, pd.DataFrame]:
    min_beta = float(user_inputs["min_beta"]); max_beta = float(user_inputs["max_beta"])
    goal = user_inputs["goal"]; horizon_years = int(user_inputs["horizon"])

    bench = _download_index_close("ACWI")
    if bench is None or bench.empty:
        raise ValueError("Could not fetch ACWI benchmark.")

    all_ticks = universal_equity_universe()
    us_ticks = [t for t in all_ticks if not t.endswith(".L")][:scan_cap_us]
    uk_ticks = [t for t in all_ticks if t.endswith(".L")][:scan_cap_uk]

    rows = []
    def process(bucket: List[str]):
        for t in bucket:
            df = _download_ohlcv(t)
            if df is None or len(df) < 50 or "Close" not in df.columns: continue
            close = df["Close"].dropna()
            beta = _calculate_beta_vs(close, bench)
            if beta is None or not (min_beta <= beta <= max_beta): continue
            avg_vol = float(df["Volume"].dropna().tail(60).mean()) if "Volume" in df.columns else 0.0
            mom3 = _total_return(close, 63)
            mom6 = _total_return(close, 126)
            mom12 = _total_return(close, 252)
            vol = _volatility(close.pct_change().dropna())
            mdd = _max_drawdown(close)
            dy = _ttm_dividend_yield(t, float(close.iloc[-1]))
            rows.append((t, beta, avg_vol, mom3, mom6, mom12, vol, mdd, dy))

    process(us_ticks); process(uk_ticks)

    if not rows:
        return pd.DataFrame(columns=["Ticker","Beta","Score"]), pd.DataFrame(columns=["Ticker","Avg Volume (60d)"])

    eq = pd.DataFrame(rows, columns=[
        "Ticker","Beta","Avg Volume (60d)","3M Return","6M Return","12M Return","Volatility","Max Drawdown","Dividend Yield"
    ])

    for col in ["Avg Volume (60d)","3M Return","6M Return","12M Return","Volatility","Max Drawdown","Dividend Yield","Beta"]:
        eq[col] = pd.to_numeric(eq[col], errors="coerce")

    w = _equity_weights(goal, horizon_years)
    score = (
        _normalize(eq["3M Return"])   * w.get("mom3",0) +
        _normalize(eq["6M Return"])   * w.get("mom6",0) +
        _normalize(eq["12M Return"])  * w.get("mom12",0) +
        _normalize(eq["Volatility"], invert=True) * w.get("vol",0) +
        _normalize(eq["Max Drawdown"], invert=True) * w.get("dd",0) +
        _normalize(eq["Dividend Yield"]) * w.get("yield",0)
    )
    eq["Score"] = score.fillna(0.0)
    eq = eq.sort_values(["Score","Avg Volume (60d)"], ascending=[False, False]).head(want_equities).reset_index(drop=True)

    us_debt = _scrape_us_bond_etfs()
    uk_debt = _scrape_uk_bond_etfs()
    debt_list: list[str] = []
    if not us_debt.empty: debt_list += us_debt["Ticker"].astype(str).tolist()
    if not uk_debt.empty: debt_list += uk_debt["Ticker"].astype(str).tolist()
    debt_list = list(dict.fromkeys([t.strip().upper() for t in debt_list]))
    debt_df = _validate_rank_debt(debt_list, want_debt)

    return eq, debt_df

# ------------------- Step 2: Build & Show ------------------- #
if "user_inputs" in st.session_state:
    st.header("Step 2: Global Universe (US & UK) + Goal/Horizon Scoring")
    with st.spinner("Building US+UK universe, computing betas & goal/horizon scores..."):
        try:
            equities_df, debt_df = dynamic_universal_picker(
                st.session_state["user_inputs"],
                scan_cap_us=250, scan_cap_uk=200, want_equities=50, want_debt=30
            )
        except Exception as e:
            st.error(f"Universe build failed: {e}")
            equities_df, debt_df = pd.DataFrame(), pd.DataFrame()

    st.subheader("Candidate Equities")
    if equities_df.empty:
        st.warning("No equities matched your beta range. Try a different risk profile.")
    else:
        st.dataframe(equities_df, use_container_width=True)

    st.subheader("Debt ETFs (ranked by liquidity)")
    if debt_df.empty:
        st.warning("No bond ETFs found this run. Try again later.")
    else:
        st.dataframe(debt_df, use_container_width=True)